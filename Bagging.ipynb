{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "a5LjD3aYFmM7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xvhdD1D2FjZn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Default.csv\")\n",
        "df[\"default\"] = df[\"default\"].astype(\"category\")\n",
        "df[\"student\"] = df[\"student\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (df[\"default\"] == \"Yes\").values\n",
        "df[\"student_dummy\"] = (df[\"student\"] == \"Yes\").astype(int)\n",
        "columnas_posibles = [\"balance\", \"income\", \"student_dummy\"]\n",
        "x = df[columnas_posibles]\n",
        "columnas_posibles = x.columns"
      ],
      "metadata": {
        "id": "cvjblP5KGQUv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy LogisticRegresion"
      ],
      "metadata": {
        "id": "maUZ9kTeIpzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[columnas_posibles]"
      ],
      "metadata": {
        "id": "62hDl7RaKGgE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr = make_pipeline(StandardScaler(), lr)\n",
        "lr.fit(X, y)\n",
        "y_pred = lr.predict(X)\n",
        "accuracy = np.mean(y_pred == y)\n",
        "print(\"Accuracy del modelo:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avCybvAtovar",
        "outputId": "03f703ee-0da5-41ae-ca7d-6118675f6feb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del modelo: 0.9733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Punto extra"
      ],
      "metadata": {
        "id": "RFTxH_93PuD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred = lr.predict_proba(X)[:, 1]\n",
        "auc_score= roc_auc_score(y, y_pred)\n",
        "print(\"AUC del modelo:\", auc_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnr85or8pD_c",
        "outputId": "c2cfaec5-0099-4d0f-ba8c-a4a710c78a57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC del modelo: 0.9495553275422935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accuracy de Bagging"
      ],
      "metadata": {
        "id": "7K1ZEl8kKR_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B = 5000\n",
        "n_boot = 5000\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "for b in range(B):\n",
        "\n",
        "    cols_elegidas = np.random.choice(columnas_posibles, size=2, replace=False)\n",
        "\n",
        "    X_full = df[cols_elegidas].values\n",
        "\n",
        "    X_b, y_b = resample(\n",
        "        X_full,\n",
        "        y,\n",
        "        replace=True,\n",
        "        n_samples=n_boot\n",
        "    )\n",
        "\n",
        "    tree = DecisionTreeClassifier()\n",
        "    tree.fit(X_b, y_b)\n",
        "\n",
        "    y_pred_full = tree.predict(X_full)\n",
        "\n",
        "    all_preds.append(y_pred_full)\n",
        "\n",
        "preds_matrix = np.vstack(all_preds)\n",
        "\n",
        "y_pred_bagging = (preds_matrix.mean(axis=0) >= 0.5).astype(int)\n",
        "\n",
        "accuracy_bagging = np.mean(y_pred_bagging == y)\n",
        "\n",
        "print(\"Accuracy del modelo bagging con árboles y bootstrap:\",\n",
        "      accuracy_bagging)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqRUt5JDPJ_l",
        "outputId": "6b13ee58-5ea5-4c88-a9c5-933d833d2e34"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del modelo bagging con árboles y bootstrap: 0.9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparación\n",
        "En el modelo de regresión logística simple me da un accuracy de 0.9733, mientras que el bagging con árboles y bootstrap me da un accuracy de 0.9846. El modelo de árboles de decisión obtiene un accuracy superior, esto puede ser ya que los árboles capturan relaciones no lineales entre variables, aparte de que con el bagging se reduce la varianza del modelo, con un solo árbol se sobreajusta, pero con bootstrap y bagging cada árbol comete errores diferentes y así el modelo final es mucho más estable."
      ],
      "metadata": {
        "id": "aBFWNS2luC_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusión\n",
        "El modelo de bagging con árboles de decisión se mostro con un accuracy de 0.9846 más alto a la regresión logística que es 0.9733.\n",
        "\n",
        "Esta mejora se debe a que el bagging combina múltiples árboles sobre muestras de bootstrap del conjunto original, con lo cual se reduce la varianza. Además, con la moda permite una predicción final más estable y por ello se produce un predictor más preciso."
      ],
      "metadata": {
        "id": "YYRR2urM01Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAgmZrlJ2Fgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}